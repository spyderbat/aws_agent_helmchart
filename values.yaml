# Default values for aws_agent_helmchart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Image location for the Spyderbat AWS agent
image:
  registry: public.ecr.aws
  # Full image
  repository: a6j2k0g1/aws-agent
  tag: latest
  pullPolicy: Always
  pullSecrets: []


# Reasonable resource defaults.  May need to be larger for particularly large aws environments
resources:
  requests:
    cpu: 100m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 2048Mi

# Our recommended approach for managing the aws api credentials is to use
# a kubernetes service accounts that assumes an IAM role.
serviceAccount:
  # Set enabled to true if you want to create a service account for the agent and have
  # it assume an AWS role for interacting with AWS (recommended)
  enabled: true

  # Set create to true if you want the helm chart to create the service account for you
  create: true

  # The name of the service account to use (or create)
  name: aws-agent-serviceaccount

  # Use the below annotation for EKS based clusters to associate the service account with an IAM role
  awsRoleAnnotation: eks.amazonaws.com/role-arn
  # Provide the ARN to the role with the appropriate trust policy and
  # permissions to interact with AWS services that the service account will assume
  awsRoleArn: arn of the IAM role that the service account should assume


# Our recommended approach for managing the spyderbat api key is to use aws secrets manager
# to store the key. If you choose to use this approach, set enabled to true and
# specify the secret arn where the spyderbat api key is stored. The
awsSecretsManager:
  enabled: true
  secretArn: <arn of the secret in secrets manager that has the spyderbat api key>

credentials:
  # Our recommended approach for aws credential management is to use
  # a service account that assumes an IAM role (see serviceAccount above).
  # However, optionally you can specify the aws credentials to use for the
  # agent explicitly here. We recommend setting these with the
  # --set option during helm install rather than storing them in the values.yaml
  # aws_access_key_id:
  # aws_secret_access_key:

  # Our recommended approach for accessing the spyderbat registration key is
  # to use a secret manager like awsSecretsManager. However, if you are not
  # running in aws or choose not to use it, the spyderbat_registration_key can be managed
  # in a kubernetes secret as well. If you choose to do so, you can specify the
  # key in this setting. We recommend setting this with the --set option during
  # helm install, and not storing it in the values.yaml
  # spyderbat_registration_key:

# The spyderbat api url
spyderbatApiUrl: https://orc.spyderbat.com

# If the agent is installed on a cluster, you can provide the cluster_name
# here. This is useful for understanding where the agent is running
# when looking at agent health and data sources in the spyderbat ui
# cluster_name: my-cluster

# Agent aws service collection settings
awsAgentsConfigs:

  # You can configure multiple agents to run, each with their own settings

  # The aws account you want to monitor with this agent
  - aws_account_id: "<aws_account_id>"

    # Optionally, you can specify which aws role to assume to pull data
    # role_arn: arn:aws:iam::<account>:role/<spyderbat-aws-agent-role>


    # Flow control settings for the aws-agent spyderbat api send queue
    # Nr of messages in queue prior to sending
    send_buffer_size: 50

    # Flow control settings for the aws-agent spyderbat api send queue
    # Total size in bytes of messages in queue prior to sending
    send_buffer_records_bytes: 1000000

    # The send buffer max delay if less than send_buffer_size messages
    # are in the queue or send_buffer_records_bytes bytes are in the queue
    send_buffer_max_delay: 15

    # The log level for the agent
    log_level: INFO

    # AWS context and logs pulled using regular polling
    pollers:
    # Collect AWS GuardDuty findings with the guardduty poller
    - service: guardduty

      # The polling interval in seconds
      polling_interval: 30

      # The initial lookback in seconds when polling guardduty findings for the first time
      initial_lookback: 86400
      # Which regions to poll, and with what settings. You can override the
      # general settings (polling_interval and initial_loopback) per region
      # by adding these properties to the region map
      regions:
      - region: us-east-1
      - region: us-east-2
      - region: us-west-2

    # Collect information about EC2 instances with the ec2 poller
    - service: ec2

      # The polling interval in seconds
      polling_interval: 30

      # Which regions to poll, and with what settings. You can override the
      # polling_interval per region by adding it to the region map
      regions:
      - region: us-east-1
      - region: us-east-2
      - region: us-west-2

    # Collect meta information about what EKS clusters are running with the eks poller
    - service: eks
      polling_interval: 30
      regions:
      - region: us-east-1
        # If there is a spyderbat cluster monitor provisioned running
        # for the cluster, specify the spyderbat cluster_uid mapping to
        # the eks cluster name here, so that spyderbat can associate the
        # eks meta information with the kubernetes information pulled
        # via the kubernetes api
        provisioned_clusters:
          <eks-cluster-name>: <spyderbat-cluster-uid>
      - region: us-east-2
      - region: us-west-1
      - region: us-west-2
    - service: iam
      polling_interval: 30

    # Collect audit logs from EKS clusters with the kinesis feed for eks-audit
    # logs.
    # kinesis:
    #   - region: us-west-1
    #     stream_name: <kinesis-stream-name>
    #     shards: []
    #     message_type: eks-audit
    #     # If there is a spyderbat cluster monitor provisioned running
    #     # for the cluster, specify the spyderbat cluster_uid mapping to
    #     # the eks cluster name here, so that spyderbat can associate the
    #     # eks meta information with the kubernetes information pulled
    #     # via the kubernetes api
    #     provisioned_clusters:
    #       <eks-cluster-name>: <spyderbat-cluster-uid>
    #   - region: us-west-2
    #     stream_name: <kinesis-stream-name>
    #     shards: []
    #     message_type: eks-audit
    #     provisioned_clusters:
    #       <eks-cluster-name>: <spyderbat-cluster-uid>




